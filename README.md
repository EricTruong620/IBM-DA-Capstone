# IBM-DA-Capstone

**Project Description:**

This project uses a combination of APIs, web scraping, and data science to analyze job data and answer three questions:

1. What are the top programming languages on demand?
2. What are the top database skills in demand?
3. What are the popular IDEs?

The project consists of seven Jupyter Notebook files:

1. `Collecting job data using api Capstone.ipynb`: This file uses the Indeed API to collect job data.
2. `Jobs_API.ipynb`: This file contains a Python class for interacting with the Kaggle's API.
3. `Web Scrapping-lab Capstone.ypynb`: This file scrapes job data from the IBM course's website.
4. `ExploreDataset Capstone.ipynb`: This file explores the collected job data and identifies preliminary insights.
5. `Datawrangling-lab.ipynb`: This file cleans and prepares the job data for analysis.
6. `ExploratoryDataAnalysis-lab.ipynb`: This file performs exploratory data analysis on the job data to answer the three questions.
7. `DataVisualizations-lab.ipynb`: This file creates visualizations of the job data to communicate the findings.

**How to Install and Run the Project:**

1. Clone this repository to your local machine.
2. Open the Jupyter Notebook application.
3. Navigate to the directory containing the Jupyter Notebook files.
4. Run the `Jobs_API.ipynb` file first and keep it running.
5. Run the `Collecting job data using api Capstone.ipynb` file next to collect the data. `Jobs_API.ipynb` can be closed after this file is completed.
6. Run the `Web Scrapping-lab Capstone.ypynb` file to webscrape the data.
7. Run the `ExploreDataset Capstone.ipynb` file to explore the collected job data.
8. Run the `Datawrangling-lab.ipynb` file to clean and prepare the job data for analysis.
9. Run the `ExploratoryDataAnalysis-lab.ipynb` file to perform exploratory data analysis on the job data and answer the three questions.
10. Run the `DataVisualizations-lab.ipynb` file to create visualizations of the job data to communicate the findings.

**How to Use the Project:**

The Jupyter Notebook files contain all the instructions needed to run the project and answer the three questions.

**Credits:**

This project was completed by Eric Truong and provided by IBM's Data Analytics Professional Certificate


**Table of Contents:**

1. Introduction
2. Data Collection
3. Data Preparation
4. Exploratory Data Analysis
5. Data Visualizations
6. Conclusion

**Introduction:**

This project uses a combination of APIs, web scraping, and data science to analyze job data and answer three questions:

1. What are the top programming languages on demand?
2. What are the top database skills in demand?
3. What are the popular IDEs?

**Data Collection:**

The first two Jupyter Notebook files collect job data from two sources: the Indeed API and the LinkedIn website. The `Collecting job data using api Capstone.ipynb` file uses the Kaggle's API to collect job data. The `Web-Scrapping-Lab Capstone.ypynb` file scrapes programming languages and annual salary from the IBM's Course website.

**Data Preparation:**

The third Jupyter Notebook file, `Datawrangling-lab.ipynb`, cleans and prepares the job data for analysis. This includes removing duplicate job postings, standardizing the data types, and imputing missing values.

**Exploratory Data Analysis:**

The fourth Jupyter Notebook file, `ExploratoryDataAnalysis-lab.ipynb`, performs exploratory data analysis on the job data to answer the three questions. This includes using statistical analysis and data visualization to identify trends and patterns in the data.

**Data Visualizations:**

The fifth Jupyter Notebook file, `DataVisualizations-lab.ipynb`, creates visualizations of the job data to communicate the findings. This includes charts and graphs that show the distribution of the data and the relationships between different variables.

**Conclusion:**

This project demonstrates how to use a combination of APIs, web scraping, and data science to analyze job data and answer meaningful questions. The findings of this project can be used by job seekers to identify the skills and technologies that are in demand, and by employers to identify the skills and technologies that they need to hire.
